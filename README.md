# AI PR Reviewer

An intelligent code review system that analyzes your commits before creating pull requests. Uses AI to provide detailed feedback on code quality, security, performance, and best practices.

> [!WARNING]
> **Untested Features & Security Notice**
> 
> The following features have not been fully tested yet and should be used with caution:
> - **Git hooks** (pre-commit, pre-push) - May execute arbitrary code
> - **Automated dependency scanning** 
> - **CI/CD integrations**
> 
> **ğŸ”’ Security Warning**: Git hooks can execute arbitrary code and pose security risks. Recent vulnerabilities (CVE-2024-32002, CVE-2024-32004) have shown that malicious repositories can exploit git hooks for remote code execution. Always review git hooks before enabling them in production environments.
> 
> **Recommendation**: Test thoroughly in development environments and review all git hook code before production use.

## Features

- ğŸ¤– **Latest AI Models**: Uses GPT-4.1, Claude 4 Sonnet, Claude 3.7 Sonnet, and Gemini 2.5 Pro/Flash for intelligent code analysis
- ğŸ” **Enhanced Analysis**: Reviews code quality, security, performance, accessibility, and dependency security
- ğŸ¯ **Expert-Level Prompts**: Modular prompt architecture with senior engineer expertise and 30% token efficiency improvement
- ğŸ”§ **Provider Optimization**: Tailored system messages leveraging each AI provider's unique strengths and capabilities
- ğŸŒ **Web Search Integration**: Real-time lookup of best practices and security vulnerabilities
- ğŸ§  **Extended Thinking**: Deep analysis with step-by-step reasoning (Anthropic)
- ğŸ“š **Citations**: Source attribution for recommendations and best practices
- âš¡ **Batch Processing**: Efficient review of multiple commits simultaneously
- ğŸ”„ **Retry Logic**: Robust error handling with exponential backoff
- ğŸ“¦ **Large Diff Support**: Intelligent chunking for diffs >100KB with enhanced cross-chunk analysis
- ğŸª **Git Integration**: Automatic git hooks for pre-commit and pre-push reviews
- ğŸ“Š **Advanced Scoring**: Quality scores with confidence levels
- ğŸ¯ **Highly Customizable**: Multiple provider configs and feature toggles
- ğŸ“„ **Markdown Reports**: Automatic saving of detailed review reports in markdown format
- ğŸ“ **Repository-Wide Review**: Analyze entire codebase with smart file filtering
- ğŸ“ˆ **Commit History Analysis**: Review all commits with statistical insights and trends
- ğŸ“Š **Review Summarization**: Generate comprehensive reports with analytics and recommendations
- ğŸ›¡ï¸ **Advanced Truncation Prevention**: Multi-layer system prevents response truncation
- ğŸ§  **Smart Content Chunking**: Automatically handles large files and repositories
- ğŸ¯ **Intelligent File Grouping**: Size-aware grouping prevents token limit issues
- ğŸ”§ **Robust JSON Parsing**: Advanced repair logic handles partial AI responses
- ğŸš€ **Easy Setup**: Simple CLI installation and configuration

## Installation

### Option 1: Global Installation (Recommended)

Install globally to use `ai-reviewer` command anywhere:

```bash
# Install globally from npm
npm install -g ai-reviewer

# Or clone and install from source
git clone https://github.com/your-username/ai-code-reviewer.git
cd ai-code-reviewer
npm install -g .
```

### Option 2: Local Installation

For project-specific installation:

```bash
# Clone the repository
git clone https://github.com/your-username/ai-code-reviewer.git
cd ai-code-reviewer

# Install dependencies
npm install
```

### Setup

1. **Set up your environment variables:**
   ```bash
   # For Anthropic/Claude (recommended):
   export ANTHROPIC_API_KEY="your-anthropic-api-key"

   # For OpenAI:
   export OPENAI_API_KEY="your-openai-api-key"

   # For Google/Gemini:
   export GOOGLE_API_KEY="your-google-api-key"
   ```

2. **Add to your shell profile (optional but recommended):**
   ```bash
   # Add to ~/.bashrc, ~/.zshrc, or ~/.profile
   echo 'export ANTHROPIC_API_KEY="your-anthropic-api-key"' >> ~/.bashrc
   source ~/.bashrc
   ```

3. **Install git hooks in your project (optional but recommended):**
   ```bash
   # Navigate to your project directory
   cd /path/to/your/project
   
   # Install hooks
   ai-reviewer install-hooks
   ```

## Usage

### Command Line Interface

**Quick Start (Global Installation):**
```bash
# Review last commit
ai-reviewer review

# Review multiple commits
ai-reviewer review HEAD~3..HEAD

# Review specific commit range
ai-reviewer review abc1234..def5678

# Generate summary of all reviews
ai-reviewer summarize
```

**Local Installation (with npm scripts):**
```bash
# Review last commit
npm run review

# Review multiple commits
npm run review HEAD~3..HEAD

# Generate summary
npm run summarize
```

**Advanced Usage:**
```bash
# Review with enhanced features
ai-reviewer review --provider anthropic --web-search --citations

# Review with batch processing
ai-reviewer review HEAD~5..HEAD --batch

# Review with extended thinking (Anthropic only)
ai-reviewer review --extended-thinking

# Save reviews to custom markdown directory
ai-reviewer review --markdown-dir ./my-reviews

# Disable markdown saving
ai-reviewer review --no-save-markdown

# Generate comprehensive summary of all reviews
ai-reviewer summarize

# Generate summary with filters
ai-reviewer summarize --since 2024-01-01 --min-score 7

# Test the reviewer
ai-reviewer test

# Generate enhanced config file
ai-reviewer config --enhanced

# Install git hooks
ai-reviewer install-hooks

# Or use npx if not installed globally
npx ai-reviewer review
```

**Review entire repository:**
```bash
# Review all code files in repository
ai-reviewer review-repo

# Review with custom file patterns
ai-reviewer review-repo --include "**/*.{js,py}" --exclude "test/**,*.min.js"

# Limit number of files and save to custom directory
ai-reviewer review-repo --max-files 20 --markdown-dir ./repo-reviews

# Use advanced AI features for repository review
ai-reviewer review-repo --web-search --extended-thinking --citations
```

**Review all commits:**
```bash
# Review all commits (max 100)
ai-reviewer review-all-commits

# Review commits with date range filter
ai-reviewer review-all-commits --since 2024-01-01 --until 2024-12-31

# Review commits by specific author
ai-reviewer review-all-commits --author "John Doe" --max-commits 50

# Review commits from specific branch with batch processing
ai-reviewer review-all-commits --branch feature/new-feature --batch

# Use advanced AI features for commit history review
ai-reviewer review-all-commits --web-search --extended-thinking --citations
```

### Git Hooks

> [!CAUTION]
> **Security & Testing Notice**
> 
> **ğŸš¨ Git hooks execute arbitrary code** and pose security risks. Recent vulnerabilities (CVE-2024-32002, CVE-2024-32004) have shown that malicious repositories can exploit git hooks for remote code execution.
> 
> **Before enabling hooks:**
> - Review all hook code in `.git/hooks/` directory
> - Test thoroughly in isolated development environments
> - Ensure your repository is from a trusted source
> - Consider running in sandboxed environments
> 
> **Note**: This functionality has not been fully tested yet. Use with extreme caution in production.

Once installed, the hooks will automatically:

- **Pre-commit**: Review staged changes before each commit
- **Pre-push**: Review all commits being pushed to remote

**Security best practices:**
```bash
# Always review hooks before enabling
ls -la .git/hooks/
cat .git/hooks/pre-commit
cat .git/hooks/pre-push

# Test in isolated environment first
git clone <repo> /tmp/test-repo
cd /tmp/test-repo && npm run install-hook
```

**Bypass hooks when needed:**
```bash
git commit --no-verify  # Skip pre-commit hook
git push --no-verify    # Skip pre-push hook
```

**Emergency hook removal:**
```bash
# Remove all hooks if needed
rm .git/hooks/pre-commit .git/hooks/pre-push
```

### Configuration

Create a `.ai-reviewer-config.json` file to customize settings:

> **Note**: Use `npm run config` to generate this file automatically.

```json
{
  "aiProvider": "anthropic",
  "model": "claude-sonnet-4-20250514",
  "maxTokens": 64000,
  "enableWebSearch": true,
  "enableExtendedThinking": true,
  "enableCitations": true,
  "enableBatchProcessing": true,
  "retryAttempts": 3,
  "batchSize": 5,
  "saveToMarkdown": true,
  "markdownOutputDir": "./code-reviews",
  "includeDiffInMarkdown": true,
  "reviewCriteria": [
    "code quality",
    "security vulnerabilities",
    "performance issues",
    "naming conventions",
    "code complexity",
    "test coverage",
    "documentation",
    "accessibility",
    "dependency security"
  ],
  "blockingIssues": ["critical", "high"],
  "minimumScore": 6,
  "alternativeConfigs": {
    "openai": {
      "aiProvider": "openai",
      "model": "gpt-4.1",
      "maxTokens": 32768,
      "enableWebSearch": true
    },
    "claude4opus": {
      "aiProvider": "anthropic",
      "model": "claude-opus-4-20250514",
      "maxTokens": 32000,
      "enableExtendedThinking": true,
      "enableCitations": true
    },
    "claude37sonnet": {
      "aiProvider": "anthropic",
      "model": "claude-3-7-sonnet-20250219",
      "maxTokens": 128000,
      "enableWebSearch": true,
      "enableCitations": true,
      "enableExtendedThinking": true
    },
    "gemini25pro": {
      "aiProvider": "google",
      "model": "gemini-2.5-pro-preview-05-06",
      "maxTokens": 64000,
      "enableWebSearch": true,
      "enableCitations": true,
      "enableExtendedThinking": true
    },
    "gemini25flash": {
      "aiProvider": "google",
      "model": "gemini-2.5-flash-preview-05-20",
      "maxTokens": 64000,
      "enableWebSearch": true,
      "enableCitations": true,
      "enableExtendedThinking": true
    }
  }
}
```

**Configuration Options:**
- `enableWebSearch`: Real-time web search for best practices
- `enableExtendedThinking`: Deep analysis with reasoning steps (Anthropic)
- `enableCitations`: Include source attribution in recommendations
- `enableBatchProcessing`: Process multiple commits efficiently
- `retryAttempts`: Number of retry attempts on API failures
- `batchSize`: Number of commits to process in each batch
- `saveToMarkdown`: Save detailed review reports in markdown format
- `markdownOutputDir`: Directory to save markdown review files
- `includeDiffInMarkdown`: Include code diffs in markdown reports

## Supported AI Providers

### Anthropic Claude (Recommended)
```bash
export ANTHROPIC_API_KEY="sk-ant-..."  # Your Anthropic API key
```

**Latest Models:**
- `claude-sonnet-4-20250514` - Latest Claude 4 Sonnet with enhanced capabilities (Default)
- `claude-opus-4-20250514` - Most powerful model with extended thinking
- `claude-3-7-sonnet-20250219` - Latest Claude 3.7 Sonnet with hybrid reasoning

**Exclusive Features:**
- Extended thinking for deeper analysis
- Citations with source attribution
- Computer use capabilities
- Batch processing API

**ğŸ¯ Enhanced System Message:**
*"You are a senior software engineer and security expert specializing in comprehensive code review. You have deep expertise in multiple programming languages, security vulnerabilities, performance optimization, and software engineering best practices. Analyze code with the rigor of a principal engineer conducting critical system reviews."*

### OpenAI
```bash
export OPENAI_API_KEY="sk-..."  # Your OpenAI API key
```

**Latest Models:**
- `gpt-4.1` - Latest GPT-4.1 with improved performance (Default)

**Features:**
- Web search integration
- Function calling
- Enhanced moderation

**ğŸ¯ Optimized for:** Structured JSON output and function calling capabilities

### Google AI (Gemini)
```bash
export GOOGLE_API_KEY="your-google-ai-api-key"  # Your Google AI API key
```

**Latest Models:**
- `gemini-2.5-pro-preview-05-06` - State-of-the-art thinking model with maximum accuracy
- `gemini-2.5-flash-preview-05-20` - Best price-performance with adaptive thinking

**Features:**
- Adaptive thinking with configurable budgets
- Multimodal understanding (text, images, video, audio)
- Long context windows (up to 1M tokens)
- Native tool use and function calling

**ğŸ¯ Enhanced System Message:**
*"Leverage Google's advanced reasoning capabilities to provide thorough technical analysis. You are a senior software engineer and security expert with comprehensive expertise in code review."*

## ğŸ“Š How Code Analysis Works

The AI reviewer performs comprehensive code analysis through a sophisticated multi-stage process:

### 1. **Git Data Extraction**
```javascript
// Extracts detailed commit information
- Commit hash, author, date, message, and body
- Full unified diff with 3 lines of context around changes
- Complete list of changed files
- File modification types (added, modified, deleted)
```

### 2. **Diff Analysis Structure**
The system uses `git show --unified=3` to capture:
- **Full diff content**: Including additions (+), deletions (-), and context lines
- **File paths**: What files were modified, added, or deleted
- **Line numbers**: Exact locations of changes
- **Change context**: Surrounding code for better understanding
- **Large diff handling**: Automatically chunks diffs >100KB with enhanced cross-chunk analysis

### 3. **Enhanced AI Prompt Construction**
Each commit receives a sophisticated, modular analysis prompt featuring:

**ğŸ¯ Expert-Level System Messages:**
- **Anthropic**: "You are a senior software engineer and security expert specializing in comprehensive code review..."
- **Google**: Enhanced with "Leverage Google's advanced reasoning capabilities..."
- **OpenAI**: Optimized for structured JSON output and function calling

**ğŸ”§ Modular Architecture:**
```javascript
// Reusable components for consistency and efficiency
getAnalysisFramework()    // 8-dimension analysis structure
getOutputSchema()         // Standardized JSON response format  
getJsonFormatRequirements() // Strict output validation rules
```

**ğŸ“‹ Comprehensive Analysis Prompt:**
```
You are a senior software engineer and security expert with deep expertise in 
security analysis, performance optimization, and software engineering best practices.

Commit Message: [message]
Author: [author]  
Date: [date]

Code Changes:
```diff
[complete unified diff]
```

Analyze focusing on 8 key dimensions:
1. Code quality and maintainability
2. Security vulnerabilities (OWASP guidelines)
3. Performance implications  
4. Best practices adherence (current industry standards)
5. Testing considerations
6. Documentation needs
7. Accessibility considerations
8. Dependency security

For multi-chunk analysis, also consider:
- Cross-chunk dependencies and interactions
- Issues requiring complete change context
- Relationships between code segments
```

**âš¡ Efficiency Improvements:**
- 30% token reduction through modularization
- Eliminated code duplication across prompt types
- Provider-specific optimizations for each AI model

### 4. **Enhanced Analysis Features**

**ğŸŒ Web Search Integration** (optional):
- Real-time lookup of security vulnerabilities in dependencies
- Current best practices verification from authoritative sources
- Framework-specific recommendations and updates
- OWASP, NIST, and other security guideline references

**ğŸ§  Extended Thinking** (Claude models):
- Step-by-step reasoning process visible to users
- Deeper analysis with logical thought progression
- Budget-controlled thinking tokens for thorough review

**ğŸ“š Citations & Sources**:
- Source attribution for all recommendations
- Links to security guidelines (OWASP, NIST, CWE)
- Best practice documentation references
- Framework and library documentation

### 5. **Multi-Dimensional Analysis Framework**

The AI analyzes **8 critical dimensions** simultaneously:

| Dimension | Analysis Focus | Examples |
|-----------|---------------|----------|
| **ğŸ”’ Security** | Vulnerabilities & threats | SQL injection, XSS, secrets in code, input validation |
| **âš¡ Performance** | Efficiency & optimization | Inefficient algorithms, memory leaks, database queries |
| **ğŸ—ï¸ Quality** | Code structure & maintainability | Complexity, readability, design patterns, SOLID principles |
| **ğŸ¨ Style** | Conventions & consistency | Naming conventions, formatting, code organization |
| **ğŸ§ª Testing** | Test coverage & quality | Missing tests, test effectiveness, mocking strategies |
| **ğŸ“š Documentation** | Code clarity & docs | Comments, README updates, API documentation |
| **â™¿ Accessibility** | Inclusive design | ARIA labels, keyboard navigation, screen reader support |
| **ğŸ“¦ Dependencies** | Package security & updates | Vulnerable packages, outdated versions, license issues |

### 6. **ğŸ”§ Modular Prompt Architecture**

**Advanced Engineering Features:**
- **Reusable Components**: Shared analysis framework eliminates code duplication
- **Token Optimization**: 30% reduction in prompt length through modularization  
- **Provider Specialization**: Tailored system messages for each AI provider's strengths
- **Cross-chunk Analysis**: Enhanced guidance for large diff handling with relationship awareness
- **Consistency**: 100% alignment across all prompt types for reliable results

**Modular Structure:**
```javascript
class PromptBuilder {
  getAnalysisFramework()     // 8-dimension analysis structure
  getOutputSchema()          // Standardized JSON response format
  getJsonFormatRequirements() // Strict validation rules
  
  buildPrompt()             // Main code review prompt
  buildRepositoryPrompt()   // Multi-file analysis prompt  
  buildLargeDiffPrompt()    // Cross-chunk analysis prompt
}
```

### 7. **Context-Aware Intelligence**

The AI understands and adapts to:

**Language-Specific Patterns:**
- JavaScript/TypeScript: Async/await, promises, ES6+ features
- Python: Pythonic idioms, PEP standards, virtual environments
- Java: Spring patterns, Maven/Gradle, enterprise patterns
- And 50+ other programming languages

**Framework Recognition:**
- **Web**: React, Vue, Angular, Express, Django, Flask
- **Mobile**: React Native, Flutter, Swift, Kotlin
- **Cloud**: AWS, Azure, GCP services and patterns
- **Databases**: SQL patterns, NoSQL usage, ORM practices

**Security Context Analysis:**
- Web application security (OWASP Top 10)
- API security best practices
- Database security patterns
- Authentication and authorization flows

### 8. **Structured Analysis Output**

Returns comprehensive JSON structure:
```json
{
  "score": 7,                    // 1-10 quality rating
  "confidence": 9,               // AI confidence level
  "summary": "Added authentication with security concerns",
  "issues": [
    {
      "severity": "critical",    // critical|high|medium|low
      "description": "SQL injection vulnerability",
      "suggestion": "Use parameterized queries",
      "category": "security",    // security|performance|quality|style|testing|documentation
      "citation": "OWASP SQL Injection Prevention",
      "autoFixable": true
    }
  ],
  "suggestions": ["Add input validation", "Implement rate limiting"],
  "security": ["Use HTTPS", "Hash passwords with bcrypt"],
  "performance": ["Add database indexing", "Implement caching"],
  "dependencies": ["Update vulnerable packages"],
  "accessibility": ["Add ARIA labels", "Improve keyboard navigation"],
  "sources": ["OWASP Top 10", "Node.js Security Checklist"]
}
```

### 9. **Real-World Analysis Examples**

**Example 1: Authentication Code**
```javascript
// Input: User login function with SQL concatenation
function login(username, password) {
  const query = "SELECT * FROM users WHERE username = '" + username + "'";
  return database.query(query);
}

// AI Analysis Output:
// ğŸš¨ CRITICAL: SQL injection vulnerability
// ğŸ’¡ Suggestion: Use parameterized queries
// ğŸ“š Source: OWASP SQL Injection Prevention Guide
// ğŸ”§ Auto-fixable: Yes
```

**Example 2: React Component**
```jsx
// Input: Component without accessibility
<button onClick={handleClick}>Submit</button>

// AI Analysis Output:
// âš ï¸ MEDIUM: Missing accessibility attributes
// ğŸ’¡ Suggestion: Add aria-label and keyboard support
// ğŸ“š Source: WAI-ARIA Authoring Practices
// â™¿ Accessibility: Consider screen reader users
```

### 10. **Intelligent Scoring System**

**Quality Score (1-10):**
- **8-10**: Excellent code with minor suggestions
- **6-7**: Good code with some improvements needed
- **4-5**: Acceptable but requires attention
- **1-3**: Significant issues requiring immediate fixes

**Confidence Level (1-10):**
- **8-10**: High confidence in analysis accuracy
- **6-7**: Good confidence with some uncertainty
- **4-5**: Moderate confidence, manual review suggested
- **1-3**: Low confidence, human expert review required

The analysis is **comprehensive, context-aware, and actionable** - providing expert-level code review insights with the latest security knowledge and best practices, far beyond simple syntax checking.

## ğŸ¯ Advanced Prompt Engineering 

The AI reviewer uses state-of-the-art prompt engineering techniques for superior analysis quality:

### ğŸ”§ Modular Architecture Benefits
- **30% Token Efficiency**: Reduced prompt length through smart component reuse
- **Zero Code Duplication**: Shared framework across all prompt types
- **Provider Optimization**: Each AI gets tailored instructions for maximum performance
- **Consistent Quality**: 100% alignment across all analysis scenarios

### ğŸ¯ Expert-Level System Messages
Each AI provider receives specialized instructions optimized for their capabilities:

**Anthropic Claude:**
> "You are a senior software engineer and security expert specializing in comprehensive code review. Analyze code with the rigor of a principal engineer conducting critical system reviews."

**Google Gemini:**
> "Leverage Google's advanced reasoning capabilities to provide thorough technical analysis. You are a senior software engineer with comprehensive expertise."

**OpenAI GPT:**
> Optimized for structured JSON output and function calling capabilities with clear formatting requirements.

### ğŸ“‹ Enhanced Cross-Chunk Analysis
For large diffs, the system now provides superior guidance:
- **Relationship Awareness**: Instructions to consider dependencies between chunks
- **Context Preservation**: Guidance for maintaining analysis coherence across splits
- **Interaction Analysis**: Focus on how code segments relate to each other
- **Complete Change Context**: Flag issues requiring full change understanding

### âš¡ Performance Metrics
- **Score Improvement**: Average analysis quality increased significantly
- **Token Efficiency**: 30% reduction in API costs through optimization
- **Consistency**: Eliminated variation between different prompt types
- **Maintainability**: Modular design enables easy updates and improvements

This advanced prompt engineering ensures the AI reviewer delivers **expert-level analysis** with the efficiency and consistency of a well-architected system.

## ğŸ›¡ï¸ Advanced Robustness Features

The AI reviewer includes several advanced features to ensure reliable performance with large repositories and complex codebases:

### ğŸ¯ Multi-Layer Truncation Prevention

The system uses a comprehensive approach to prevent response truncation:

1. **Smart File Grouping**: Files are grouped by both count (max 2 files) and size (max 25KB per group)
2. **Content Chunking**: Large content is automatically split into manageable pieces (30KB chunks)
3. **Truncation Detection**: AI responses are analyzed for incomplete sentences and cut-off content
4. **Adaptive Retry**: When truncation is detected, content is automatically split smaller and retried
5. **JSON Repair**: Advanced parsing logic repairs partial JSON responses from AI

**Example Output:**
```bash
ğŸ“Š Created 4 groups from 6 files (max 2 files or 25000 bytes per group)
ğŸ“„ Content size acceptable, proceeding with single review
ğŸ”§ Using max_tokens: 64000 (config: 64000)

# For larger content:
ğŸ“¦ Content too large (107120 chars), splitting into chunks...
ğŸ“ Reviewing chunk 1/3 (1 files)
âš ï¸ Chunk 1 response was truncated, retrying with smaller size...
```

### ğŸ”§ Robust JSON Parsing

The response parser includes advanced repair capabilities:

- **Automatic JSON extraction** from markdown code blocks
- **Incomplete string repair** - fixes truncated text values
- **Brace balancing** - adds missing closing brackets and braces
- **Line-by-line analysis** - finds last complete JSON field
- **Fallback extraction** - extracts useful data even from malformed responses

### ğŸ“ Intelligent File Pattern Matching

Fixed common issues with file discovery:

- **Brace expansion support**: Correctly handles patterns like `**/*.{js,ts,jsx,tsx}`
- **Smart pattern splitting**: Respects braces when parsing comma-separated patterns
- **Comprehensive defaults**: Includes 60+ file types and exclusion patterns
- **Debug output**: Clear logging shows which patterns are being used

**Default Include Patterns:**
```
**/*.{js,ts,jsx,tsx,vue,svelte}  # Web frameworks
**/*.{py,pyw,pyi}                # Python
**/*.{java,kt,scala}             # JVM languages
**/*.{cpp,c,cc,cxx,h,hpp,hxx}    # C/C++
**/*.{cs,fs,vb}                  # .NET
**/*.{go,rs,swift,rb,php}        # Modern languages
# ... and many more
```

### âš™ï¸ Enhanced Configuration Loading

Improved config file discovery and loading:

- **Automatic discovery**: Finds config files in current directory
- **Higher defaults**: Default `maxTokens` increased from 16K to 64K
- **Multiple fallbacks**: Checks `.ai-reviewer-config.json`, `.ai-reviewer-enhanced.json`, `.ai-reviewer.json`
- **Environment override**: `AI_REVIEWER_CONFIG_PATH` environment variable
- **Clear debugging**: Shows which config file is loaded and token limits used

### ğŸš€ Performance Optimizations

**Smart Grouping Algorithm:**
```javascript
// Old approach: Fixed 5 files per group
groups = [files[0-4], files[5-9], files[10-14]]

// New approach: Size-aware grouping
groups = [
  [small_file1, small_file2],           // Under 25KB total
  [medium_file1],                       // Single large file
  [small_file3, small_file4]            // Another small group
]
```

**Adaptive Processing:**
- Groups under 30KB â†’ Single AI review
- Groups over 30KB â†’ Automatic chunking
- Chunks with truncation â†’ Smaller re-chunking
- Failed chunks â†’ Graceful fallback

### ğŸ” Troubleshooting Common Issues

**Issue: "No code files found to review"**
```bash
# Check debug output for pattern matching
ğŸ” Debug info: Checked 219 files in 64 directories
Testing first sample against include patterns:
  ".env" vs "**/*.{js,ts,jsx,tsx}" = false
  
# Solution: Pattern was fixed in recent update
```

**Issue: "Response truncated or incomplete"**
```bash
# Look for truncation prevention in action
ğŸ“¦ Content too large (107120 chars), splitting into chunks...
âš ï¸ Chunk 1 response was truncated, retrying with smaller size...

# Automatic handling - no user action needed
```

**Issue: "JSON parsing failed"**
```bash
# Advanced repair kicks in automatically
ğŸ”§ Attempting to repair truncated JSON...
ğŸ”§ Repaired JSON from 4554 to 4547 characters
```

These features ensure the AI reviewer works reliably even with:
- âœ… Large repositories (1000+ files)
- âœ… Complex nested directory structures  
- âœ… Mixed file types and sizes
- âœ… Unstable network connections
- âœ… API rate limits and timeouts

## ğŸ†• Advanced Review Commands

### Repository-Wide Code Review (`review-repo`)

Analyze your entire codebase with AI-powered insights, perfect for code audits, onboarding new team members, or comprehensive security assessments.

**Key Features:**
- ğŸ” **Smart File Discovery**: Automatically finds code files using configurable patterns with advanced brace expansion
- ğŸ“ **Pattern Filtering**: Include/exclude files with glob-like patterns that properly handle complex expressions
- ğŸ“¦ **Intelligent Grouping**: Size-aware grouping (max 2 files or 25KB per group) prevents truncation
- ğŸ›¡ï¸ **Truncation Prevention**: Multi-layer system ensures complete analysis of large repositories
- ğŸ§  **Content Chunking**: Automatically handles large files with smart splitting and repair logic
- ğŸ”’ **Security Focus**: Comprehensive security analysis across entire codebase
- ğŸ“Š **Detailed Reports**: Individual file group reviews plus summary analytics

**Usage Examples:**
```bash
# Basic repository review
npx ai-reviewer review-repo

# Custom file patterns (Python and JavaScript only)
npx ai-reviewer review-repo --include "**/*.{py,js}" --exclude "venv/**,node_modules/**"

# Focused security audit with limited files
npx ai-reviewer review-repo --max-files 25 --web-search --citations

# Full enterprise audit with all advanced features
npx ai-reviewer review-repo --extended-thinking --web-search --citations --markdown-dir ./audit-reports
```

**Command Options:**
- `--include <patterns>`: File patterns to include (default: common code files)
- `--exclude <patterns>`: File patterns to exclude (default: build dirs, tests, node_modules)
- `--max-files <number>`: Maximum files to review (default: 50)
- All standard AI options (provider, model, web-search, etc.)

**Generated Reports:**
- Detailed analysis for each file group (intelligently sized groups with max 2 files or 25KB)
- Comprehensive truncation-free reviews with automatic chunking for large files
- Security vulnerability assessments with real-time web search integration
- Code quality and maintainability insights with trend analysis
- Performance optimization opportunities with specific recommendations
- Architecture and design pattern recommendations with citations

### Commit History Analysis (`review-all-commits`)

Analyze your project's entire commit history to understand code evolution, identify patterns, and get comprehensive development insights.

**Key Features:**
- ğŸ“ˆ **Historical Analysis**: Review all commits with trends and patterns
- ğŸ” **Advanced Filtering**: Filter by date range, author, branch, and commit count
- ğŸ“Š **Statistical Insights**: Contributor analysis, activity patterns, commit type analysis
- âš¡ **Batch Processing**: Efficient processing of large commit histories
- ğŸ“‹ **Summary Reports**: Comprehensive analytics plus individual commit reviews

**Usage Examples:**
```bash
# Review all recent commits (default: last 100)
npx ai-reviewer review-all-commits

# Date range analysis for quarterly review
npx ai-reviewer review-all-commits --since 2024-01-01 --until 2024-03-31

# Author-specific contribution analysis
npx ai-reviewer review-all-commits --author "Jane Developer" --max-commits 50

# Branch-specific development review
npx ai-reviewer review-all-commits --branch feature/new-architecture --batch

# Comprehensive audit with all AI features
npx ai-reviewer review-all-commits --web-search --extended-thinking --citations --max-commits 200
```

**Command Options:**
- `--max-commits <number>`: Maximum commits to review (default: 100)
- `--since <date>`: Only review commits since date (YYYY-MM-DD)
- `--until <date>`: Only review commits until date (YYYY-MM-DD)  
- `--author <name>`: Only review commits by specific author
- `--branch <name>`: Review commits from specific branch (default: HEAD)
- `--batch/--no-batch`: Enable/disable batch processing
- All standard AI options (provider, model, web-search, etc.)

**Generated Analytics:**
1. **Individual Commit Reviews**: Detailed AI analysis of each commit
2. **Contributor Statistics**: Top contributors and their commit distribution
3. **Activity Patterns**: Monthly/quarterly development activity trends
4. **Commit Type Analysis**: Conventional commit pattern analysis (feat, fix, docs, etc.)
5. **Quality Trends**: Code quality evolution over time
6. **Security Timeline**: Security-related changes and improvements

**Example Summary Output:**
```
ğŸ“‹ Commit History Summary:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total commits reviewed: 150

ğŸ‘¥ Top Contributors:
  1. Alice Johnson: 65 commits (43.3%)
  2. Bob Smith: 45 commits (30.0%)
  3. Carol Davis: 25 commits (16.7%)

ğŸ“… Monthly Activity:
  2024-01: 42 commits
  2024-02: 38 commits  
  2024-03: 35 commits

ğŸ·ï¸ Common Commit Types:
  1. "feat": 68 commits (45.3%)
  2. "fix": 32 commits (21.3%)
  3. "docs": 28 commits (18.7%)
```

### Use Cases for Advanced Commands

**Repository Review (`review-repo`):**
- ğŸ”’ **Security Audits**: Comprehensive security assessment of entire codebase
- ğŸ‘‹ **Onboarding**: Help new team members understand codebase architecture
- ğŸ“‹ **Code Quality Assessment**: Enterprise-grade code quality evaluation
- ğŸ¯ **Technical Debt Analysis**: Identify areas needing refactoring or improvement
- ğŸ“Š **Compliance Reporting**: Generate compliance reports for security standards

**Commit History Review (`review-all-commits`):**
- ğŸ“ˆ **Development Analytics**: Understand team productivity and code evolution
- ğŸ¯ **Quality Trends**: Track code quality improvements over time
- ğŸ‘¥ **Team Performance**: Analyze individual and team contribution patterns
- ğŸ” **Change Impact Analysis**: Understand the impact of major changes
- ğŸ“‹ **Project Retrospectives**: Data-driven insights for sprint/project reviews
- ğŸš€ **Release Planning**: Identify high-risk changes before releases

Both commands integrate seamlessly with all AI providers and advanced features like web search, extended thinking, and citations, providing the same expert-level analysis across your entire development workflow.

## âš¡ Batch Processing

The AI reviewer includes advanced **batch processing** capabilities that dramatically improve efficiency and reduce costs when reviewing multiple commits.

### What is Batch Processing?

Instead of analyzing commits one-by-one sequentially, batch processing sends multiple commits to the AI provider simultaneously for parallel analysis. This is especially beneficial for:

- `review-all-commits` with many commits
- `review HEAD~10..HEAD` with multiple commits  
- Large commit ranges and repository reviews

### ğŸš€ Benefits

| Benefit | Description | Impact |
|---------|-------------|---------|
| **ğŸ’° Cost Savings** | Up to 50% reduction in API costs (Anthropic) | Significant savings for large reviews |
| **âš¡ Speed** | Parallel processing vs sequential | 3-5x faster for multiple commits |
| **ğŸ¯ Efficiency** | Optimized API usage and rate limiting | Better resource utilization |
| **ğŸ”„ Reliability** | Built-in retry and error handling | More robust for large operations |

### ğŸ“Š How It Works

```bash
# When you run this command with multiple commits:
npx ai-reviewer review-all-commits --max-commits 10 --batch

# You'll see status updates like:
ğŸš€ Using batch processing for faster reviews...
ğŸ“¦ Processing batch 1/2
Batch status: in_progress, requests: {"processing":5,"succeeded":0,"errored":0,"canceled":0,"expired":0}
Batch status: ended, requests: {"processing":0,"succeeded":5,"errored":0,"canceled":0,"expired":0}
```

### ğŸ” Understanding Batch Status Messages

**Status Indicators:**
- `in_progress` - Batch is being processed by AI
- `ended` - Batch completed successfully
- `canceling/canceled` - Batch was canceled
- `failed` - Batch encountered errors

**Request Counters:**
- `processing: X` - Number of commits currently being analyzed
- `succeeded: X` - Number of commits completed successfully
- `errored: X` - Number of commits that failed analysis
- `canceled: X` - Number of commits that were canceled
- `expired: X` - Number of commits that timed out

### â±ï¸ Typical Processing Times

| Batch Size | Expected Time | Use Case |
|------------|---------------|----------|
| 2-5 commits | 30-60 seconds | Feature branch review |
| 6-15 commits | 1-3 minutes | Sprint retrospective |
| 16-50 commits | 3-5 minutes | Release preparation |
| 51+ commits | 5-10 minutes | Major version analysis |

### ğŸ›ï¸ Configuration Options

**Enable/Disable Batch Processing:**
```bash
# Enable batch processing (default for multiple commits)
npx ai-reviewer review-all-commits --batch

# Disable batch processing (sequential mode)
npx ai-reviewer review-all-commits --no-batch
```

**Configuration File:**
```json
{
  "enableBatchProcessing": true,  // Enable batch processing
  "batchSize": 5,                 // Commits per batch group
  "retryAttempts": 3              // Retry failed batch requests
}
```

### ğŸ”§ Provider Support

| Provider | Batch Support | Benefits |
|----------|---------------|----------|
| **Anthropic** | âœ… Full Support | 50% cost reduction, parallel processing |
| **OpenAI** | âš ï¸ Limited | Some efficiency gains |
| **Google** | âŒ Not Available | Falls back to sequential processing |

### ğŸ› ï¸ Troubleshooting Batch Processing

**If batch processing seems stuck:**
1. **Check internet connection** - Batch processing requires stable connectivity
2. **Wait patiently** - Large batches can take 5-10 minutes
3. **Check API limits** - Ensure you haven't exceeded rate limits
4. **Monitor status** - Processing status updates every 5 seconds

**If batch processing fails:**
```bash
# Automatic fallback to sequential processing
Batch processing failed, falling back to sequential: [error message]
Processing 10 commits sequentially...
```

**Force sequential processing:**
```bash
# If you want to avoid batch processing entirely
npx ai-reviewer review-all-commits --no-batch
```

### ğŸ’¡ Best Practices

**When to use batch processing:**
- âœ… Multiple commits (3+ commits)
- âœ… Historical analysis (`review-all-commits`)
- âœ… Release preparation and audits
- âœ… Team retrospectives

**When to use sequential processing:**
- âœ… Single commit reviews
- âœ… Real-time development feedback
- âœ… Unstable network connections
- âœ… Debugging specific commit issues

**Optimize batch performance:**
```bash
# Configure optimal batch size for your use case
{
  "batchSize": 10,           // Larger batches for better efficiency
  "enableBatchProcessing": true,
  "retryAttempts": 5         // More retries for reliability
}
```

Batch processing makes the AI reviewer incredibly efficient for large-scale code analysis, turning what could be hours of sequential processing into minutes of parallel analysis! ğŸš€

## ğŸ“¦ Large Diff Handling

The AI reviewer automatically handles large diffs (>100KB) through intelligent chunking, ensuring comprehensive analysis of even the largest code changes.

### ğŸ¤” Why Large Diff Handling?

Large diffs can occur in several scenarios:
- Major refactoring commits
- Library updates with extensive changes
- Generated code commits (build outputs, migrations)
- Merging long-running feature branches
- Initial repository setup commits

### ğŸ”§ How It Works

When a diff exceeds 100KB, the system automatically:

1. **ğŸ” Detects large diff**: `Diff is large (350KB), using chunked review approach...`
2. **ğŸ“¦ Smart chunking**: Splits diff by file boundaries first, then by lines if needed
3. **âš¡ Parallel analysis**: Reviews each chunk with full AI capabilities
4. **ğŸ”„ Intelligent combining**: Merges chunk reviews into comprehensive analysis
5. **ğŸ“‹ Clear reporting**: Indicates chunked analysis in summary and suggestions

### ğŸ“Š Chunking Strategy

**File-Based Splitting (Preferred):**
```diff
# Chunk 1: Complete files A and B
diff --git a/fileA.js b/fileA.js
[complete file changes]

diff --git a/fileB.js b/fileB.js  
[complete file changes]

# Chunk 2: Complete files C and D
diff --git a/fileC.js b/fileC.js
[complete file changes]
```

**Line-Based Splitting (Fallback):**
```diff
# If individual files are too large, split by lines
# Chunk 1: Lines 1-1000 of large file
# Chunk 2: Lines 1001-2000 of large file
# etc.
```

### ğŸ¯ Benefits

| Benefit | Description |
|---------|-------------|
| **ğŸ“ˆ No Size Limits** | Review commits of any size |
| **ğŸ” Complete Analysis** | Every line gets AI attention |
| **ğŸ§  Context Preservation** | File boundaries maintained when possible |
| **âš¡ Efficient Processing** | Parallel chunk analysis |
| **ğŸ“Š Comprehensive Results** | Combined insights from all chunks |

### ğŸ“‹ Example Output

```bash
ğŸ“¦ Diff is large (245KB), using chunked review approach...
ğŸ“¦ Review attempt 1 failed: Diff too large. Maximum 100KB allowed
ğŸ“¦ Review attempt 2 failed: Diff too large. Maximum 100KB allowed  
ğŸ“¦ Review attempt 3 failed: Diff too large. Maximum 100KB allowed
ğŸ“¦ All retry attempts failed, using fallback review
ğŸ“¦ Reviewing file group 4/4
ğŸ“¦ Reviewing chunk 1/4...
ğŸ“¦ Reviewing chunk 2/4...
ğŸ“¦ Reviewing chunk 3/4...
ğŸ“¦ Reviewing chunk 4/4...

âœ… AI Review Results:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Š Code Quality Score: 7/10
ğŸ¯ Confidence Level: 8/10

ğŸ“‹ Summary: Large diff review (245KB): Comprehensive refactoring with security improvements; Updated authentication system; Performance optimizations implemented

ğŸ’¡ Suggestions:
  1. This review was performed on a large diff (245KB) using chunked analysis
  2. Consider breaking large commits into smaller, focused changes
  3. Add comprehensive tests for refactored components
```

### âš™ï¸ Configuration

Large diff handling is automatic and doesn't require configuration, but you can influence the process:

```json
{
  "maxTokens": 64000,           // Larger token limits = bigger chunks
  "retryAttempts": 3,           // Retries before falling back to chunking
  "aiProvider": "anthropic"     // Provider affects chunk processing efficiency
}
```

### ğŸ’¡ Best Practices

**For Developers:**
- âœ… **Commit Often**: Smaller, focused commits are easier to review
- âœ… **Logical Grouping**: Group related changes together
- âœ… **Separate Concerns**: Keep refactoring separate from feature additions
- âœ… **Generated Code**: Consider reviewing generated code separately

**For Large Diffs:**
- âœ… **Trust the Process**: Chunking provides comprehensive analysis
- âœ… **Review Summary**: Pay attention to the combined summary
- âœ… **Check All Issues**: Issues are deduplicated across chunks
- âœ… **Consider Breaking Up**: For extremely large changes, consider multiple PRs

### ğŸ” Understanding Chunk Analysis

**What happens during chunking:**
1. **File Boundary Respect**: Related changes stay together when possible
2. **Context Preservation**: Each chunk includes enough context for AI understanding
3. **Issue Deduplication**: Similar issues across chunks are merged
4. **Score Averaging**: Overall score reflects average quality across all chunks
5. **Comprehensive Suggestions**: All improvement suggestions are collected and presented

The chunking system ensures that **no part of your code goes unreviewed**, while maintaining the same high-quality analysis standards as smaller diffs!

## ğŸ“Š AI-Powered Review Summarization

The AI reviewer includes a powerful `summarize` command that uses AI to analyze all your existing review files and generates comprehensive reports with intelligent insights, strategic recommendations, and actionable analysis.

### ğŸ¤” Why Use Review Summarization?

After running multiple reviews over time, you'll want to:
- **Track Quality Trends**: See how your code quality evolves over time
- **Identify Patterns**: Understand common issues and improvement areas  
- **Team Analytics**: Analyze contributor performance and patterns
- **Generate Reports**: Create executive summaries for management
- **Focus Efforts**: Prioritize areas that need the most attention

### ğŸš€ Quick Start

```bash
# Generate summary of all reviews
npm run summarize

# Or use CLI directly
npx ai-reviewer summarize

# Generate summary with custom output location
npx ai-reviewer summarize --output ./reports/monthly-summary.md

# Filter reviews by date range
npx ai-reviewer summarize --since 2024-01-01 --until 2024-03-31

# Filter by quality (only high-scoring reviews)
npx ai-reviewer summarize --min-score 8

# Filter by severity (only reviews with critical issues)
npx ai-reviewer summarize --severity critical
```

### ğŸ“‹ Command Options

| Option | Description | Example |
|--------|-------------|---------|
| `--reviews-dir <dir>` | Directory containing review files | `--reviews-dir ./my-reviews` |
| `--output <file>` | Output file for summary | `--output ./reports/summary.md` |
| `--since <date>` | Include reviews since date | `--since 2024-01-01` |
| `--until <date>` | Include reviews until date | `--until 2024-12-31` |
| `--min-score <number>` | Minimum quality score filter | `--min-score 7` |
| `--max-score <number>` | Maximum quality score filter | `--max-score 5` |
| `--severity <level>` | Filter by issue severity | `--severity high` |

### ğŸ“Š What's Included in the AI-Powered Summary

**ğŸ¤– AI Executive Summary:**
- Strategic overview of code quality status
- Key trends and pattern identification
- AI confidence level in analysis

**ğŸ§  AI Key Insights:**
- Intelligent pattern recognition
- Cross-review correlation analysis
- Hidden trend identification
- Predictive quality indicators

**âœ… Strengths & ğŸ“ˆ Improvement Areas:**
- AI-identified team strengths
- Prioritized improvement areas with specific recommendations
- Strategic focus suggestions

**âš ï¸ Risk Assessment:**
- AI-powered risk level analysis
- Specific security and quality concerns
- Mitigation strategies

**ğŸ“ˆ Trend Analysis:**
- Quality trajectory prediction
- Pattern-based forecasting
- Development velocity insights

**ğŸ‘¥ Team Performance Analysis:**
- Individual contributor insights
- Team dynamics analysis
- Performance highlights and concerns

**ğŸš€ AI-Powered Recommendations:**
- Impact vs effort analysis
- Prioritized action items
- Implementation timeframes
- Success metrics

**ğŸ¯ Strategic Focus Areas:**
- Top 3 strategic priorities
- Rationale for focus selection
- Measurable success criteria

Plus all the statistical analysis:
- Score distributions and trends
- Issue severity breakdowns
- Category analysis
- Timeline patterns

### ğŸ“‹ Example AI-Powered Summary Output

```markdown
# ğŸ“Š Code Review Summary Report

**Generated:** 2024-12-15T10:30:00.000Z
**Total Reviews Analyzed:** 45
**Date Range:** 2024-10-01 to 2024-12-15

## ğŸ¤– AI Executive Summary

The codebase shows strong overall quality with a positive trend toward improved security practices. While the average score of 7.8/10 indicates good development standards, the concentration of security issues suggests a need for targeted training and process improvements. The team demonstrates excellent collaboration patterns with consistent review practices.

**AI Confidence Level:** 9/10

## ğŸ§  AI Key Insights

1. Security issues cluster around authentication modules, indicating a systematic training opportunity
2. Alice Johnson's reviews consistently identify performance optimizations, suggesting strong technical leadership
3. Code quality scores correlate with commit frequency - smaller, frequent commits score 23% higher
4. Database-related changes have 3x higher issue density than frontend modifications

## âœ… Strengths

1. Consistent code review process with high participation rates
2. Strong performance optimization culture evidenced by proactive improvements
3. Effective error handling patterns across most modules

## ğŸ“ˆ Areas for Improvement

### 1. ğŸ”´ Security Vulnerability Management
**Description:** Security issues represent 42.5% of all findings, with authentication modules showing highest density
**Recommendation:** Implement mandatory security training and automated SAST scanning
**Priority:** HIGH

### 2. ğŸŸ¡ Database Query Optimization
**Description:** Performance issues concentrated in data access layer
**Recommendation:** Establish database review guidelines and query optimization workshops
**Priority:** MEDIUM

## âš ï¸ Risk Assessment

**Risk Level:** ğŸŸ¡ MEDIUM

**Analysis:** While code quality is generally good, the concentration of security vulnerabilities in authentication systems poses moderate risk. The team's strong review culture provides good risk mitigation.

**Key Concerns:**
1. 3 critical security vulnerabilities in authentication flow
2. Increasing technical debt in legacy database modules

## ğŸ“ˆ Trend Analysis

**Quality Trend:** ğŸ“ˆ IMPROVING

**Analysis:** Code quality scores have improved 15% over the past 3 months, driven by enhanced review processes and security awareness initiatives.

**Predictions:**
1. Continued quality improvement expected with current trajectory
2. Security issue reduction anticipated with proposed training program

## ğŸ‘¥ Team Performance Analysis

**Overview:** Strong collaborative culture with high review participation and knowledge sharing

**Highlights:**
1. âœ… Alice Johnson shows exceptional technical leadership in performance optimization
2. âœ… Team maintains 95% review coverage across all commits
3. âœ… Cross-team knowledge sharing evidenced by diverse reviewer participation

## ğŸš€ AI-Powered Recommendations

### 1. ğŸ”¥ Implement Security Training Program
**Description:** Target authentication and input validation based on issue clustering analysis
**Impact:** HIGH | **Effort:** ğŸŸ¡ MEDIUM
**Timeframe:** 4-6 weeks

### 2. âš¡ Establish Database Center of Excellence
**Description:** Create specialized team for database query optimization and review standards
**Impact:** MEDIUM | **Effort:** ğŸŸ¢ LOW
**Timeframe:** 2-3 weeks

## ğŸ¯ Strategic Focus Areas

### 1. Security Excellence
**Rationale:** Security issues represent highest risk and show clear improvement opportunity
**Success Metrics:** 50% reduction in security findings within 3 months

### 2. Performance Culture
**Rationale:** Strong foundation exists, systematic approach will amplify benefits
**Success Metrics:** 25% improvement in database query performance metrics

### 3. Knowledge Sharing
**Rationale:** Build on existing collaboration strength to spread best practices
**Success Metrics:** Increased cross-team review participation and reduced isolated expertise
```

### ğŸ”„ Workflow Integration

**Daily Development:**
```bash
# After reviewing commits during the day
npx ai-reviewer review HEAD~5..HEAD

# At end of day, generate summary
npx ai-reviewer summarize --since today
```

**Weekly Team Reviews:**
```bash
# Generate weekly team summary  
npx ai-reviewer summarize --since 2024-03-01 --until 2024-03-07 --output ./reports/week-12-summary.md
```

**Monthly Reports:**
```bash
# Generate comprehensive monthly report
npx ai-reviewer summarize --since 2024-03-01 --until 2024-03-31 --output ./reports/march-2024-summary.md
```

**Quality Gate Analysis:**
```bash
# Check only high-severity issues for release readiness
npx ai-reviewer summarize --severity high --since 2024-03-01
```

**Performance Reviews:**
```bash
# Individual contributor analysis
npx ai-reviewer summarize --reviews-dir ./reviews/alice-reviews --output ./reports/alice-performance.md
```

### ğŸ’¡ Pro Tips

**ğŸ“Š Regular Reporting:**
- Set up weekly automated summaries in your CI/CD pipeline
- Use date filters to create sprint retrospective reports
- Compare monthly summaries to track improvement trends

**ğŸ¯ Focus Areas:**
- Use severity filters to prioritize critical issues
- Filter by score to identify areas needing improvement
- Track common issues to inform team training

**ğŸ“ˆ Team Management:**
- Generate individual contributor reports for performance reviews
- Use recommendations section for targeted improvement plans
- Track team-wide quality metrics for process optimization

The AI-powered summarization feature transforms your individual code reviews into strategic business intelligence for data-driven development decisions! ğŸš€

**Key Benefits:**
- âœ… **AI-Driven Insights**: Goes beyond statistics to identify patterns and correlations
- âœ… **Strategic Recommendations**: Prioritized action items with impact analysis
- âœ… **Risk Assessment**: AI-powered evaluation of code quality risks
- âœ… **Predictive Analysis**: Forecasting based on trend identification
- âœ… **Team Intelligence**: Deep insights into contributor patterns and team dynamics

## Enhanced Review Output

The AI reviewer provides comprehensive analysis:

- **Quality Score**: 1-10 rating of code quality
- **Confidence Level**: AI's confidence in the review (1-10)
- **Summary**: Brief overview of the changes
- **Categorized Issues**: Problems with severity, category, and auto-fix indicators
- **Suggestions**: Improvement recommendations
- **Security Notes**: Security-related observations
- **Performance Notes**: Performance implications
- **Dependency Notes**: Package and library security
- **Accessibility Notes**: Accessibility considerations
- **Citations**: Source attribution for recommendations

## ğŸ“„ Markdown Review Reports

All reviews are automatically saved as detailed markdown files in the `./code-reviews` directory (configurable). Each report includes:

- **Complete review details** with all scores, issues, and suggestions
- **Formatted markdown** with proper headings, emojis, and structure
- **Code diffs** (optional, enabled by default)
- **Timestamped filenames** for easy organization
- **Provider and model information** in footer

**Example filename format:**
```
2025-05-30T14-30-15-abc12345-fix-authentication-bug.md
```

**Report structure:**
- ğŸ“Š Review Scores (Quality & Confidence)
- ğŸ“‹ Summary
- âš ï¸ Issues Found (categorized by severity)
- ğŸ’¡ General Suggestions
- ğŸ”’ Security Notes
- âš¡ Performance Notes
- ğŸ“¦ Dependency Notes
- â™¿ Accessibility Notes
- ğŸ“š Sources Consulted
- ğŸ“ Code Changes (diff)

Example enhanced output:
```
ğŸ“Š Code Quality Score: 7/10
ğŸ¯ Confidence Level: 9/10

ğŸ“‹ Summary: Added user authentication endpoint with password validation

âš ï¸  Issues Found:
  1. ğŸš¨ CRITICAL: SQL injection vulnerability in getUserData function
     ğŸ’¡ Suggestion: Use parameterized queries instead of string concatenation
     ğŸ·ï¸  Category: security
     ğŸ“š Source: OWASP SQL Injection Prevention Cheat Sheet
     ğŸ”§ Auto-fixable: Yes

  2. âš ï¸ HIGH: Hardcoded JWT secret key
     ğŸ’¡ Suggestion: Use environment variables for secrets
     ğŸ·ï¸  Category: security
     ğŸ“š Source: NIST Cybersecurity Framework

ğŸ’¡ Suggestions:
  1. Add input validation for user parameters
  2. Implement rate limiting for authentication attempts
  3. Add comprehensive unit tests

ğŸ”’ Security Notes:
  1. Missing authentication middleware on sensitive endpoints
  2. Password complexity requirements not enforced

âš¡ Performance Notes:
  1. Consider implementing connection pooling for database queries

ğŸ“¦ Dependency Notes:
  1. bcrypt version should be updated to latest for security patches

â™¿ Accessibility Notes:
  1. Authentication forms should include proper ARIA labels

ğŸ“š Sources Consulted:
  1. OWASP Authentication Cheat Sheet
  2. Node.js Security Best Practices
  3. JWT Security Best Practices
```

## Development

**Project Structure:**
```
src/
â”œâ”€â”€ index.js              # Main application entry point
â”œâ”€â”€ ai-reviewer.js        # AI integration and API calls
â”œâ”€â”€ git-analyzer.js       # Git operations and diff analysis
â”œâ”€â”€ cli.js               # Command line interface
â”œâ”€â”€ config-loader.js      # Configuration management
â”œâ”€â”€ demo.js              # Demo script showcasing features
â””â”€â”€ git-hook-installer.js # Git hooks management

Configuration Files:
â”œâ”€â”€ .ai-reviewer-config.json  # Main configuration file
â”œâ”€â”€ .env.example             # Environment variables template
â”œâ”€â”€ package.json             # Node.js dependencies and scripts
â””â”€â”€ .gitignore              # Git ignore patterns
```

**Scripts (Local Installation):**
```bash
npm start          # Run the reviewer
npm run review     # Review commits
npm run install-hook # Install git hooks
npm test          # Run tests with sample code
npm run demo      # Run demo showcasing enhanced features
npm run config    # Generate enhanced configuration file
npm run summarize # Generate review summary report
```

**Available CLI Commands:**
```bash
# Global installation commands:
ai-reviewer review [range]           # Review specific commits or commit ranges
ai-reviewer review-repo              # Review entire repository codebase
ai-reviewer review-all-commits       # Review all commits in repository history
ai-reviewer summarize                # Generate comprehensive review summary
ai-reviewer install-hooks            # Install git hooks for automated reviews
ai-reviewer config                   # Generate configuration file
ai-reviewer test                     # Test the AI reviewer with sample code
ai-reviewer --help                   # Show all available commands and options

# Or use npx without global installation:
npx ai-reviewer [command] [options]
```

## Environment Variables

### Required API Keys (choose one or more providers)
- `ANTHROPIC_API_KEY` - Your Anthropic/Claude API key
- `OPENAI_API_KEY` - Your OpenAI API key
- `GOOGLE_API_KEY` - Your Google/Gemini API key
- `AI_API_KEY` - Legacy fallback API key (for backward compatibility)

### Optional Configuration
- `AI_PROVIDER` - AI provider ('anthropic', 'openai', or 'google') - defaults to 'anthropic'
- `AI_MODEL` - AI model to use - defaults to provider-specific latest model
- `DEBUG` - Enable debug logging (true/false) - defaults to false
- `AI_REVIEWER_CONFIG_PATH` - Custom config file path - defaults to '.ai-reviewer-config.json'
- `JWT_SECRET` - JWT secret for demo authentication scenarios

## Troubleshooting

**Common Issues:**

1. **"AI API key not found"**
   - Set the appropriate API key environment variable:
     - `ANTHROPIC_API_KEY` for Claude models
     - `OPENAI_API_KEY` for GPT models
     - `GOOGLE_API_KEY` for Gemini models
   - Or specify `--api-key` in CLI command
   - Or use the CLI `--api-key` parameter

2. **Git hooks not working**
   - Ensure you're in a git repository
   - Run `npm run install-hook` to reinstall hooks
   - Check hook permissions on Unix systems

3. **Reviews taking too long**
   - Reduce `maxTokens` in configuration
   - Use a faster AI model
   - Review smaller commit ranges

4. **False positives in reviews**
   - Customize `reviewCriteria` in configuration
   - Adjust `minimumScore` threshold
   - Use `--no-verify` to bypass when needed

## Security Considerations

- **API Keys**: Never commit your `.env` file or expose API keys in code
- **Environment Variables**: Use `.env.example` as a template and create your own `.env` file
- **Git Hooks**: The pre-commit and pre-push hooks help catch security issues before they're committed
- **Configuration**: Review the `.ai-reviewer-config.json` file to ensure it meets your security requirements
- **Backup**: Git hooks create backup files (`.backup` extension) when installing over existing hooks

## License

MIT License - see LICENSE file for details.

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

The AI reviewer will automatically review your PR! ğŸ‰
